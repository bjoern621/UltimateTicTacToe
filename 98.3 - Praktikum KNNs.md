Forschungsfrage: Kann durch ein KNN ein zufälliger Spielzustand eines UTTT Spieles akkurat eingeschätzt werden?

1. Baseline festlegen
	- einfachstes Modell: Immer das wahrscheinlichste Ergebnis, bei UTTT "Spieler X", unabhängig vom Spielstand zurückgeben
		- Dieses Modell hätte eine Genauigkeit von ~45%
2. Datenbeschaffung
	- Nach unseren Recherchen existiert kein Datensatz, welcher eine große Menge von UTTT Spielen abbildet.
	  Da wir jedoch bereits eine UTTT Implementation mit verschiedenen Algorithmen in unserer Arbeit zu Baumsuchverfahren entwickelt haben, konnten wir diese nutzen, um unsere eigenen Testdaten zu generieren. Um einen repräsentativen Datensatz zu generieren, verwenden wir zufällige, valide Boardzustände, von welchen aus bewährte Algorithmen weiterspielen.
	  Dafür simulieren wir für Spieler X und Spieler O einen Random-Actor bis zu einer zufällig gewählten Rundenzahl, sodass wir einen zufälligen Boardzustand erhalten. Dieser Boardzustand, einschließlich des erzwungenen Boards, wird abgespeichert. Von dieser Runde ausgehend spielen zwei Minimax-Akteure mit einer Suchtiefe von 5 Iterationen so lange weiter, bis das Spiel beendet wurde. Dabei wird der Boardzustand nach jedem Zug erneut gespeichert. Abschließend werden alle Boardzustände dieses Spiels mit dem Gewinner des Spiels, also Spieler X, Y oder Unentschieden, versehen, was die Labels der Einträge darstellt.
	  Die zufällige Rundenanzahl, ab welcher durch den Minimax-Algorithmus simuliert wird, basiert auf einer normalverteilten Zufallszahl zwischen 0 und 66, der maximalen Rundenanzahl, die wir bei der vorherigen Arbeit mit UTTT ermittelt haben.
	  Durch die anfangs zufällige Simulation des Spiels erhalten wir eine breite Spannweite möglichen an Ausgangssituationen, nicht nur "optimaler Zustände für beide Spieler", auf Basis welcher unser KNN trainiert werden kann. Es kann sein, dass durch die Aufzeichnung aller Zwischenzustände eine Überrepräsentation von zufälligen Spielen, bei welchen früh die zufällige Simulation abgebrochen wurde, im Datensatz entstehen kann. Daher sind alle Spiele durch eine eindeutige Zahl gekennzeichnet, welche es uns im Nachhinein ermöglicht, jeweils nur einen Zustand jedes Spiels zu verwenden.
	  Insgesamt wurden 60.000 Spiele simuliert, was zu einer Gesamtzahl von 1.316.448 Einträgen führte, somit im Schnitt 22,4408 Spielzüge pro Spiel.
3. Vorverarbeitung
	- Formatierung der Daten: Als Matrix organisieren, sodass Reihe = Datenpunkt/Label. `mat.reshape(rows, cols)`
		- Bei uns fällt die erste Zeile (Header) und die erste Spalte (Indices) weg. Vorerst fällt außerdem die letzte Spalte (Confidence) evenfalls weg.
	- Normalisierung der Wertebereiche
		- Normalisierung: Wertebereich auf $[0,1]$ legen
		- Standardisierung: Mittelwert von $0$ und Standardabweichung von $1$ für alle Testdaten
	- One-Hot-Encoding der Label: Für uns: `y_onehot = np.eye(3)[y]`
	- Aufteilung in Trainings-, Validierungs- und Testdaten:
		- 60% Trainingsdaten
		- 20% Validierungsdaten
		- 20% Testdaten
		- `x_val = x_train[50_000:60_000` und `x_train = x_train[:50_000]`
	- Shuffle
		- Da mehrere Boards desselben Spiels (somit desselben Ausgangs) aneinanderhängen, müssen die Daten vor dem Training gemischt werden, um etwaige Verzerrungen zu verhindern.
```python
np.random.seed(12)
indices = np.random.permutation(x_train.shape[0])
x_train = x_train[indices] # Datenpunkte
y_train = y_train[indices] # Label
 ```
4. Modell
	- 
5. Kostenfunktion
6. Training
7. Hyperparameter optimieren